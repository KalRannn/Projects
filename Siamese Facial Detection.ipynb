{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31cdf9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d77560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using tensorflow - Function API\n",
    "os.chdir(r'C:\\Users\\RaloP\\FaceDetection')\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd609e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avoid out of memory errors my limiting gpu memory consumption growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpy,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5af505f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup up paths\n",
    "POS_PATH = os.path.join('data','postive')\n",
    "NEG_PATH = os.path.join('data','negative')\n",
    "ANC_PATH = os.path.join('data','anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec23214",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'data\\\\postive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19744\\20321214.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Making Directories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPOS_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNEG_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mANC_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'data\\\\postive'"
     ]
    }
   ],
   "source": [
    "#Making Directories\n",
    "os.makedirs(POS_PATH)\n",
    "os.makedirs(NEG_PATH)\n",
    "os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed2ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncompress Tar Gz Labelled Faces in the Wild Dataset\n",
    "!tar -xf lfw.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving Images to data/negative repo\n",
    "for directory in os.listdir('lfw'):\n",
    "    for file in os.listdir(os.path.join('lfw',directory)):\n",
    "        EX_PATH = os.path.join('lfw',directory,file)\n",
    "        NEW_PATH = os.path.join(NEG_PATH,file)\n",
    "        os.replace(EX_PATH,NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73336bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing web cam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    #Cut Down frame to 250x250 pixels\n",
    "    frame = frame[120:120+250,200:200+250, :]\n",
    "    #Collect anchors\n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        #Create unique file path\n",
    "        imgname = os.path.join(ANC_PATH,'{}.jpg'.format(uuid.uuid1()))\n",
    "        #Write anchor image\n",
    "        cv2.imwrite(imgname,frame)\n",
    "        \n",
    "    #Collect positivies\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        #Create unique file path\n",
    "        imgname = os.path.join(POS_PATH,'{}.jpg'.format(uuid.uuid1()))\n",
    "        #Write positive image\n",
    "        cv2.imwrite(imgname,frame)\n",
    "        \n",
    "    cv2.imshow('Image Collection',frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ec7d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRABS IMAGES FROM THEIR DIRECTORY\n",
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(300)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(300)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec707200",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_test = anchor.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c5a8776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'data\\\\anchor\\\\40736ef2-392a-11ee-b8d7-744ca192b5ac.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_test.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a050cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    #Reading in image from file path\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    #Load in Image\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    #Preprocess(Reize image to 100x100x3)\n",
    "    img = tf.image.resize(img,(100,100))\n",
    "    #Scaling the image to be between 0 and 1\n",
    "    img = img/255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "108796e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
       "array([[[0.5806373 , 0.58455884, 0.564951  ],\n",
       "        [0.58210784, 0.58406866, 0.5644608 ],\n",
       "        [0.5953431 , 0.5855392 , 0.560049  ],\n",
       "        ...,\n",
       "        [0.5468137 , 0.52892154, 0.49436274],\n",
       "        [0.547549  , 0.5252451 , 0.49215686],\n",
       "        [0.54338235, 0.5276961 , 0.48455882]],\n",
       "\n",
       "       [[0.58235294, 0.58431375, 0.5647059 ],\n",
       "        [0.5772059 , 0.57279414, 0.5531863 ],\n",
       "        [0.5995098 , 0.5877451 , 0.56960785],\n",
       "        ...,\n",
       "        [0.57058823, 0.5355392 , 0.4997549 ],\n",
       "        [0.57303923, 0.5387255 , 0.50147057],\n",
       "        [0.56421566, 0.5357843 , 0.49558824]],\n",
       "\n",
       "       [[0.59166664, 0.58186275, 0.5563725 ],\n",
       "        [0.6068627 , 0.595098  , 0.5718137 ],\n",
       "        [0.6012255 , 0.58210784, 0.56911767],\n",
       "        ...,\n",
       "        [0.5296569 , 0.50416666, 0.45808825],\n",
       "        [0.53088236, 0.5009804 , 0.4512255 ],\n",
       "        [0.5504902 , 0.51911765, 0.47009805]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.889951  , 0.8664216 , 0.90563726],\n",
       "        [0.8786765 , 0.85514706, 0.89436275],\n",
       "        [0.8757353 , 0.8522059 , 0.89142156],\n",
       "        ...,\n",
       "        [0.7441176 , 0.72745097, 0.7441176 ],\n",
       "        [0.75171566, 0.735049  , 0.75171566],\n",
       "        [0.7536765 , 0.73406863, 0.75171566]],\n",
       "\n",
       "       [[0.8901961 , 0.8666667 , 0.90588236],\n",
       "        [0.89240193, 0.8688725 , 0.9080882 ],\n",
       "        [0.89240193, 0.86446077, 0.90588236],\n",
       "        ...,\n",
       "        [0.9375    , 0.9267157 , 0.9522059 ],\n",
       "        [0.9553922 , 0.94460785, 0.970098  ],\n",
       "        [0.9669118 , 0.9531863 , 0.9796569 ]],\n",
       "\n",
       "       [[0.89705884, 0.8656863 , 0.90882355],\n",
       "        [0.89681375, 0.8654412 , 0.90857846],\n",
       "        [0.89436275, 0.8629902 , 0.90612745],\n",
       "        ...,\n",
       "        [0.91813725, 0.9142157 , 0.9362745 ],\n",
       "        [0.9816176 , 0.97769606, 0.9968137 ],\n",
       "        [0.9637255 , 0.9519608 , 0.9872549 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess('data\\\\anchor\\\\19641f29-392a-11ee-85ee-744ca192b5ac.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6f2006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip(((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor))))))\n",
    "negatives = tf.data.Dataset.zip(((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor))))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53fbf822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img,validation_img,label):\n",
    "    return(preprocess(input_img), preprocess(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fea531e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building dataloader pipline\n",
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "231c5241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training partition \n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "171584c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing partition\n",
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2538da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    inp = Input(shape=(100,100,3),name='input_image')\n",
    "    #First Block\n",
    "    c1 = Conv2D(64,(10,10),activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(64,(2,2),padding='same')(c1)\n",
    "    #Second Block\n",
    "    c2 = Conv2D(128,(7,7),activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64,(2,2),padding='same')(c2)\n",
    "    #Third Block\n",
    "    c3 = Conv2D(128,(4,4),activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64,(2,2),padding='same')(c3)\n",
    "    #Fourth Block\n",
    "    c4 = Conv2D(256,(4,4),activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096,activation='sigmoid')(f1)\n",
    "    \n",
    "    return Model(inputs=[inp],outputs=[d1],name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d07ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5627e5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_image (InputLayer)    [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 91, 91, 64)        19264     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 46, 46, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 40, 40, 128)       401536    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 20, 20, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 17, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 9, 9, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 256)         524544    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38960448 (148.62 MB)\n",
      "Trainable params: 38960448 (148.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b11144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese L1 Distance Class\n",
    "class L1Dist(Layer):\n",
    "    #Init Inheritance\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "    #Similarity Calucaltion\n",
    "    def call(self,input_embedding,validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb60f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "    \n",
    "    # Anchor Input\n",
    "    input_image = Input(name='input_img',shape=(100,100,3))\n",
    "    # Validation Input\n",
    "    validation_image = Input(name='validation_img',shape=(100,100,3))\n",
    "    \n",
    "    # Combing the siamese distance compenents\n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(embedding(input_image),embedding(validation_image))\n",
    "    \n",
    "    # Classification Layer\n",
    "    classifier = Dense(1,activation='sigmoid')(distances)\n",
    "    \n",
    "    return Model(inputs=[input_image,validation_image],outputs=classifier,name='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c69a78c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "017bbd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_img (InputLayer)      [(None, 100, 100, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " validation_img (InputLayer  [(None, 100, 100, 3)]        0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)      (None, 4096)                 3896044   ['input_img[0][0]',           \n",
      "                                                          8          'validation_img[0][0]']      \n",
      "                                                                                                  \n",
      " distance (L1Dist)           (None, 4096)                 0         ['embedding[0][0]',           \n",
      "                                                                     'embedding[1][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    4097      ['distance[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38964545 (148.64 MB)\n",
      "Trainable params: 38964545 (148.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af1821d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fc99412",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b01aef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkpoints\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt,siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf260535",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    #Recording All Operations\n",
    "    with tf.GradientTape() as tape:\n",
    "        #Anchor, postive, negative image\n",
    "        X=batch[:2]\n",
    "        #Label\n",
    "        y=batch[2]\n",
    "        \n",
    "        #Forward Pass\n",
    "        yhat = siamese_model(X,training=True)\n",
    "        \n",
    "        #Find Loss\n",
    "        loss = binary_cross_loss(y,yhat)\n",
    "    print(loss)\n",
    "    \n",
    "    #Calulcate gradients\n",
    "    grad = tape.gradient(loss,siamese_model.trainable_variables)\n",
    "    \n",
    "    #Calulcate updates weights and apply to model\n",
    "    opt.apply_gradients(zip(grad,siamese_model.trainable_variables))\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6f9cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "    #Loop through epochs\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "    \n",
    "    #Loop through batchs\n",
    "    for idx, batch in enumerate(data):\n",
    "        #Train Step\n",
    "        train_step(batch)\n",
    "        progbar.update(idx+1)\n",
    "    #Save Checkpoints\n",
    "    if epoch % 10 ==0:\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17616bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "964624bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/50\n",
      "\n",
      " Epoch 2/50\n",
      "\n",
      " Epoch 3/50\n",
      "\n",
      " Epoch 4/50\n",
      "\n",
      " Epoch 5/50\n",
      "\n",
      " Epoch 6/50\n",
      "\n",
      " Epoch 7/50\n",
      "\n",
      " Epoch 8/50\n",
      "\n",
      " Epoch 9/50\n",
      "\n",
      " Epoch 10/50\n",
      "\n",
      " Epoch 11/50\n",
      "\n",
      " Epoch 12/50\n",
      "\n",
      " Epoch 13/50\n",
      "\n",
      " Epoch 14/50\n",
      "\n",
      " Epoch 15/50\n",
      "\n",
      " Epoch 16/50\n",
      "\n",
      " Epoch 17/50\n",
      "\n",
      " Epoch 18/50\n",
      "\n",
      " Epoch 19/50\n",
      "\n",
      " Epoch 20/50\n",
      "\n",
      " Epoch 21/50\n",
      "\n",
      " Epoch 22/50\n",
      "\n",
      " Epoch 23/50\n",
      "\n",
      " Epoch 24/50\n",
      "\n",
      " Epoch 25/50\n",
      "\n",
      " Epoch 26/50\n",
      "\n",
      " Epoch 27/50\n",
      "\n",
      " Epoch 28/50\n",
      "\n",
      " Epoch 29/50\n",
      "\n",
      " Epoch 30/50\n",
      "\n",
      " Epoch 31/50\n",
      "\n",
      " Epoch 32/50\n",
      "\n",
      " Epoch 33/50\n",
      "\n",
      " Epoch 34/50\n",
      "\n",
      " Epoch 35/50\n",
      "\n",
      " Epoch 36/50\n",
      "\n",
      " Epoch 37/50\n",
      "\n",
      " Epoch 38/50\n",
      "\n",
      " Epoch 39/50\n",
      "\n",
      " Epoch 40/50\n",
      "\n",
      " Epoch 41/50\n",
      "\n",
      " Epoch 42/50\n",
      "\n",
      " Epoch 43/50\n",
      "\n",
      " Epoch 44/50\n",
      "\n",
      " Epoch 45/50\n",
      "\n",
      " Epoch 46/50\n",
      "\n",
      " Epoch 47/50\n",
      "\n",
      " Epoch 48/50\n",
      "\n",
      " Epoch 49/50\n",
      "\n",
      " Epoch 50/50\n",
      "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "26/27 [===========================>..] - ETA: 13sTensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "27/27 [==============================] - 370s 13s/step\n"
     ]
    }
   ],
   "source": [
    "train(train_data,EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91338901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7fc27563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get test data\n",
    "test_input, test_val, y_true = test_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb953d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "#Make Predictions\n",
    "y_hat = siamese_model.predict([test_input,test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bdf5ad56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.6889752e-01],\n",
       "       [7.5893313e-01],\n",
       "       [8.9923579e-01],\n",
       "       [6.2437022e-05],\n",
       "       [3.2804685e-04],\n",
       "       [2.9745263e-06],\n",
       "       [9.4402158e-01],\n",
       "       [9.4987637e-01],\n",
       "       [2.9939509e-05],\n",
       "       [9.4828510e-01],\n",
       "       [9.4586074e-01],\n",
       "       [9.2154354e-01],\n",
       "       [5.7886116e-04],\n",
       "       [7.0442044e-04],\n",
       "       [1.3593493e-01],\n",
       "       [8.5507852e-01]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46fe528c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Post processing\n",
    "[1 if prediction > 0.5 else 0 for prediction in y_hat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c1f8b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a metric object\n",
    "m = Recall()\n",
    "#Calculating the recall value\n",
    "m.update_state(y_true,y_hat)\n",
    "# Return Recall Result\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "45815769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a metric object\n",
    "m = Precision()\n",
    "#Calculating the Precision value\n",
    "m.update_state(y_true,y_hat)\n",
    "# Return Precision Result\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca2295d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RaloP\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#Save weights\n",
    "siamese_model.save('siamesemodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "610a10e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#ReLoading in model\n",
    "model = tf.keras.models.load_model('siamesemodel.h5',custom_objects={'L1Dist':L1Dist,'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cb370c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.6889752e-01],\n",
       "       [7.5893313e-01],\n",
       "       [8.9923579e-01],\n",
       "       [6.2437022e-05],\n",
       "       [3.2804685e-04],\n",
       "       [2.9745263e-06],\n",
       "       [9.4402158e-01],\n",
       "       [9.4987637e-01],\n",
       "       [2.9939509e-05],\n",
       "       [9.4828510e-01],\n",
       "       [9.4586074e-01],\n",
       "       [9.2154354e-01],\n",
       "       [5.7886116e-04],\n",
       "       [7.0442044e-04],\n",
       "       [1.3593493e-01],\n",
       "       [8.5507852e-01]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([test_input,test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "413b7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(model,detection_threshold,verification_threshold):\n",
    "    results = []\n",
    "    \n",
    "    for image in os.listdir(os.path.join('application_data','verification_images')):\n",
    "        input_img = preprocess(os.path.join('application_data','input_image','input_image.jpg'))\n",
    "        validation_img = preprocess(os.path.join('application_data','verification_images',image))\n",
    "        \n",
    "        result = model.predict(list(np.expand_dims([input_img,validation_img],axis=1)))\n",
    "        results.append(result)\n",
    "    detection = np.sum(np.array(results)>detection_threshold)\n",
    "    verification = detection / len(os.listdir(os.path.join('application_data','verification_images')))\n",
    "    verified = verification > verification_threshold\n",
    "    return results, verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b0ce942b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "False\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    frame = frame[120:120+250,200:200+250, :]\n",
    "    cv2.imshow('Verification',frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
    "        cv2.imwrite(os.path.join('application_data','input_image','input_image.jpg'),frame)\n",
    "        results, verified = verify(model,0.5,0.5)\n",
    "        print(verified)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d3eedf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
